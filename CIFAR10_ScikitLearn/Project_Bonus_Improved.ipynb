{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOplP9qhIJv6"
      },
      "source": [
        "# CSE475 Project Bonus, Due: Friday, 04/29/2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgBhnOntIJv9"
      },
      "source": [
        "## Instruction\n",
        "\n",
        "1. Please submit your Jupyter Notebook file (the. ipynb file) containing your code and the outputs produced by your code (note that .ipynb file can contain both the code and the outputs) to Canvas. Please name your file CSE475-ProjectBonus-LastName-FirstName.ipynb.\n",
        "\n",
        "2. If you have any questions on the homework problems, you should post your question on the Canvas discussion board (under Project Q&A), instead of sending emails to the instructor or TA. We will answer your questions there. In this way, we can avoid repeated questions, and help the entire class stay on the same page whenever any clarification/correction is made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AQAn_3PIJv-"
      },
      "source": [
        "## Building a Convolutional Neural Network to classify images in the CIFAR-10 Dataset\n",
        "\n",
        "We will work with the CIFAR-10 Dataset.  This is a well-known dataset for image classification, which consists of 60000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "The 10 classes are:\n",
        "\n",
        "<ol start=\"0\">\n",
        "<li> airplane\n",
        "<li>  automobile\n",
        "<li> bird\n",
        "<li>  cat\n",
        "<li> deer\n",
        "<li> dog\n",
        "<li>  frog\n",
        "<li>  horse\n",
        "<li>  ship\n",
        "<li>  truck\n",
        "</ol>\n",
        "\n",
        "For details about CIFAR-10 see:\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "For a compilation of published performance results on CIFAR 10, see:\n",
        "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html\n",
        "\n",
        "---\n",
        "\n",
        "### Building CNN\n",
        "\n",
        "In this project we will build and train our convolutional neural network. In the first part, we walk through different layers and how they are configured. In the second part, you will build your own model, train it, and compare the performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiZRR4_BIJv_",
        "outputId": "ac0b8076-c92f-4023-de90-4074d70496f9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.3) (1.5.2)\n",
            "Requirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.34.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.12.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "import keras\n",
        "!pip install keras==2.4.3\n",
        "!pip install tensorflow==2.5.0\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAJM1Zg5IJwB",
        "outputId": "7b5e20ce-93e5-460e-c162-d57a4aab11cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# The data, shuffled and split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSGsqibvIJwC",
        "outputId": "3f0d17b5-5e54-4424-c85d-c60be62c19cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "## Each image is a 32 x 32 x 3 numpy array\n",
        "x_train[444].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "yfPmFIgLIJwD",
        "outputId": "ccf01aeb-afc1-4813-89a9-8ced6543e249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "## Let's look at one of the images\n",
        "\n",
        "print(y_train[444])\n",
        "plt.imshow(x_train[444]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_ltCRfvIJwE"
      },
      "outputs": [],
      "source": [
        "# convert class labels to one-hot vectors\n",
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMQaL3adIJwE",
        "outputId": "41b5e475-19d0-4cd1-9b75-0033c0a39477"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# see some one-hot vector\n",
        "y_train[444]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2cFoEtbIJwF"
      },
      "outputs": [],
      "source": [
        "# As before, let's make everything float and scale\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-P7FP-mIJwG"
      },
      "source": [
        "## First CNN\n",
        "Below we will build our first CNN.  For demonstration purpose (so that it will br trained quickly) it is not very deep and has relatively few parameters.  We use strides of 2 in the first two convolutional layers which quickly reduces the dimensions of the output. After a MaxPooling layer, we flatten, and then have a single fully connected layer before the final classification layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORzOQb6JIJwG",
        "outputId": "6ac7ce86-2a1a-4e76-bbf6-6175c8044a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 16, 16, 32)        2432      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 6, 6, 32)          25632     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 288)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               147968    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 181,162\n",
            "Trainable params: 181,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Let's build a CNN using Keras' Sequential capabilities\n",
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "## 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## Another 5x5 convolution with 2x2 stride and 32 filters\n",
        "model_1.add(Conv2D(32, (5, 5), strides = (2,2)))\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "## 2x2 max pooling reduces to 3 x 3 x 32\n",
        "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "## Flatten turns 3x3x32 into 288x1\n",
        "model_1.add(Flatten())\n",
        "model_1.add(Dense(512))\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(Dropout(0.5))\n",
        "model_1.add(Dense(num_classes))\n",
        "model_1.add(Activation('softmax'))\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qkiatT-IJwH"
      },
      "source": [
        "We still have 181K parameters, even though this is a \"small\" model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znCW2L3_IJwI",
        "outputId": "a5de2525-7b30-4954-e96f-2d6442f9f81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "391/391 [==============================] - 20s 13ms/step - loss: 2.0548 - accuracy: 0.2440 - val_loss: 1.6302 - val_accuracy: 0.4120\n",
            "Epoch 2/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.6413 - accuracy: 0.4100 - val_loss: 1.5135 - val_accuracy: 0.4600\n",
            "Epoch 3/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.4953 - accuracy: 0.4598 - val_loss: 1.4051 - val_accuracy: 0.5049\n",
            "Epoch 4/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.4087 - accuracy: 0.4934 - val_loss: 1.2898 - val_accuracy: 0.5420\n",
            "Epoch 5/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.3624 - accuracy: 0.5096 - val_loss: 1.2686 - val_accuracy: 0.5480\n",
            "Epoch 6/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.3003 - accuracy: 0.5333 - val_loss: 1.2035 - val_accuracy: 0.5746\n",
            "Epoch 7/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2663 - accuracy: 0.5509 - val_loss: 1.1730 - val_accuracy: 0.5870\n",
            "Epoch 8/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2355 - accuracy: 0.5603 - val_loss: 1.1539 - val_accuracy: 0.5987\n",
            "Epoch 9/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.2110 - accuracy: 0.5682 - val_loss: 1.1361 - val_accuracy: 0.6073\n",
            "Epoch 10/15\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1820 - accuracy: 0.5785 - val_loss: 1.1079 - val_accuracy: 0.6083\n",
            "Epoch 11/15\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1463 - accuracy: 0.5935 - val_loss: 1.1337 - val_accuracy: 0.5980\n",
            "Epoch 12/15\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1206 - accuracy: 0.6007 - val_loss: 1.1127 - val_accuracy: 0.6056\n",
            "Epoch 13/15\n",
            "391/391 [==============================] - 5s 13ms/step - loss: 1.1030 - accuracy: 0.6072 - val_loss: 1.0882 - val_accuracy: 0.6228\n",
            "Epoch 14/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0873 - accuracy: 0.6137 - val_loss: 1.0417 - val_accuracy: 0.6390\n",
            "Epoch 15/15\n",
            "391/391 [==============================] - 5s 12ms/step - loss: 1.0722 - accuracy: 0.6192 - val_loss: 1.0189 - val_accuracy: 0.6460\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd81f0ed350>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "batch_size = 128\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0005, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=15,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOsRfHwcIJwI",
        "outputId": "16980537-a49c-47d3-dfe2-a0cacb3fe37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.0189012289047241\n",
            "Test accuracy: 0.6460000276565552\n"
          ]
        }
      ],
      "source": [
        "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrPpWgInIJwJ"
      },
      "source": [
        "## Your task (25pts)\n",
        "\n",
        "Our previous model (model_1) had the structure:\n",
        "\n",
        "Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification (with activation functions and dropouts)\n",
        "\n",
        "Please built a different model (named model_2) by trying different structures and different hyperparameters, such as number of neurons, layers, stride, padding, dropout rate, kernel size, learning rate, number of epochs, etc. You can choose to add data augmentation, batch normalization and/or something new.<br>\n",
        "\n",
        "For example: <br>\n",
        "A deeper model: Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n",
        "<br>\n",
        "\n",
        "Report the best test accuracy achieved. You will be graded on the highest test accuracy achieved:<br>\n",
        "Test accuracy < Base model (model_1) : 0 - 5pts (Depending on the changes made in model_2)<br>\n",
        "Base model (model_1) < Test accuracy < 70%: 5 - 10pts (Depending on the changes made in model_2)<br>\n",
        "70% < Test accuracy < 75%: 15pts<br>\n",
        "75% < Test accuracy: 25pts <br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zXP4z1SBm8fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSCe-J8kIJwJ"
      },
      "outputs": [],
      "source": [
        "# Let's build a CNN using Keras' Sequential capabilities\n",
        "model_2 = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tdu7vj1WIJwK"
      },
      "outputs": [],
      "source": [
        "#write your code here\n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI2bvwC5IJwK",
        "outputId": "be730a29-217f-43c4-8689-d04cd302e2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import regularizers\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "weight_decay = 1e-4\n",
        "model_2.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model_2.add(Activation('elu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model_2.add(Activation('elu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_2.add(Dropout(0.2))\n",
        " \n",
        "model_2.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model_2.add(Activation('elu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model_2.add(Activation('elu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_2.add(Dropout(0.3))\n",
        " \n",
        "model_2.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model_2.add(Activation('elu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model_2.add(Activation('elu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model_2.add(Dropout(0.4))\n",
        " \n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(num_classes, activation='softmax'))\n",
        " \n",
        "model_2.summary()\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmOtd5ROIJwL",
        "outputId": "96c419bc-ddd4-4195-aa93-ea31c443ae8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "781/781 [==============================] - 84s 101ms/step - loss: 2.3483 - accuracy: 0.3397 - val_loss: 1.3582 - val_accuracy: 0.5453\n",
            "Epoch 2/150\n",
            "781/781 [==============================] - 78s 100ms/step - loss: 1.3679 - accuracy: 0.5514 - val_loss: 1.5304 - val_accuracy: 0.5818\n",
            "Epoch 3/150\n",
            "781/781 [==============================] - 80s 102ms/step - loss: 1.1145 - accuracy: 0.6367 - val_loss: 0.9324 - val_accuracy: 0.7086\n",
            "Epoch 4/150\n",
            "781/781 [==============================] - 79s 100ms/step - loss: 1.0081 - accuracy: 0.6760 - val_loss: 0.9303 - val_accuracy: 0.7152\n",
            "Epoch 5/150\n",
            "781/781 [==============================] - 80s 102ms/step - loss: 0.9395 - accuracy: 0.7064 - val_loss: 0.9085 - val_accuracy: 0.7289\n",
            "Epoch 6/150\n",
            "781/781 [==============================] - 79s 101ms/step - loss: 0.8798 - accuracy: 0.7245 - val_loss: 0.8080 - val_accuracy: 0.7641\n",
            "Epoch 7/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.8344 - accuracy: 0.7435 - val_loss: 0.7525 - val_accuracy: 0.7829\n",
            "Epoch 8/150\n",
            "781/781 [==============================] - 82s 104ms/step - loss: 0.8154 - accuracy: 0.7578 - val_loss: 0.8343 - val_accuracy: 0.7682\n",
            "Epoch 9/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.7775 - accuracy: 0.7661 - val_loss: 0.8101 - val_accuracy: 0.7726\n",
            "Epoch 10/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.7622 - accuracy: 0.7766 - val_loss: 1.1114 - val_accuracy: 0.6985\n",
            "Epoch 11/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.7497 - accuracy: 0.7831 - val_loss: 0.6995 - val_accuracy: 0.8064\n",
            "Epoch 12/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.7324 - accuracy: 0.7897 - val_loss: 0.7511 - val_accuracy: 0.7964\n",
            "Epoch 13/150\n",
            "781/781 [==============================] - 82s 104ms/step - loss: 0.7184 - accuracy: 0.7927 - val_loss: 0.7456 - val_accuracy: 0.7964\n",
            "Epoch 14/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.7224 - accuracy: 0.7930 - val_loss: 0.6633 - val_accuracy: 0.8234\n",
            "Epoch 15/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.7022 - accuracy: 0.8042 - val_loss: 0.7977 - val_accuracy: 0.7795\n",
            "Epoch 16/150\n",
            "781/781 [==============================] - 82s 106ms/step - loss: 0.6913 - accuracy: 0.8062 - val_loss: 0.7161 - val_accuracy: 0.8048\n",
            "Epoch 17/150\n",
            "781/781 [==============================] - 82s 104ms/step - loss: 0.6797 - accuracy: 0.8107 - val_loss: 0.6898 - val_accuracy: 0.8163\n",
            "Epoch 18/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.6734 - accuracy: 0.8152 - val_loss: 0.7040 - val_accuracy: 0.8127\n",
            "Epoch 19/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.6619 - accuracy: 0.8188 - val_loss: 0.6882 - val_accuracy: 0.8202\n",
            "Epoch 20/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.6716 - accuracy: 0.8162 - val_loss: 0.7308 - val_accuracy: 0.8012\n",
            "Epoch 21/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.6689 - accuracy: 0.8162 - val_loss: 0.6935 - val_accuracy: 0.8161\n",
            "Epoch 22/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.6561 - accuracy: 0.8237 - val_loss: 0.6572 - val_accuracy: 0.8264\n",
            "Epoch 23/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.6437 - accuracy: 0.8259 - val_loss: 0.6820 - val_accuracy: 0.8220\n",
            "Epoch 24/150\n",
            "781/781 [==============================] - 80s 103ms/step - loss: 0.6403 - accuracy: 0.8285 - val_loss: 0.7406 - val_accuracy: 0.8074\n",
            "Epoch 25/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.6441 - accuracy: 0.8281 - val_loss: 0.6759 - val_accuracy: 0.8234\n",
            "Epoch 26/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.6371 - accuracy: 0.8308 - val_loss: 0.6979 - val_accuracy: 0.8255\n",
            "Epoch 27/150\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.6392 - accuracy: 0.8295 - val_loss: 0.6142 - val_accuracy: 0.8422\n",
            "Epoch 28/150\n",
            "781/781 [==============================] - 96s 123ms/step - loss: 0.6392 - accuracy: 0.8285 - val_loss: 0.7353 - val_accuracy: 0.8039\n",
            "Epoch 29/150\n",
            "781/781 [==============================] - 108s 138ms/step - loss: 0.6281 - accuracy: 0.8303 - val_loss: 0.7586 - val_accuracy: 0.8012\n",
            "Epoch 30/150\n",
            "781/781 [==============================] - 97s 125ms/step - loss: 0.6270 - accuracy: 0.8326 - val_loss: 0.6880 - val_accuracy: 0.8223\n",
            "Epoch 31/150\n",
            "781/781 [==============================] - 99s 127ms/step - loss: 0.6309 - accuracy: 0.8321 - val_loss: 0.6957 - val_accuracy: 0.8205\n",
            "Epoch 32/150\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.6262 - accuracy: 0.8369 - val_loss: 0.6493 - val_accuracy: 0.8367\n",
            "Epoch 33/150\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.6235 - accuracy: 0.8360 - val_loss: 0.6086 - val_accuracy: 0.8463\n",
            "Epoch 34/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.6224 - accuracy: 0.8356 - val_loss: 0.6835 - val_accuracy: 0.8252\n",
            "Epoch 35/150\n",
            "781/781 [==============================] - 96s 123ms/step - loss: 0.6214 - accuracy: 0.8369 - val_loss: 0.6249 - val_accuracy: 0.8415\n",
            "Epoch 36/150\n",
            "781/781 [==============================] - 96s 122ms/step - loss: 0.6105 - accuracy: 0.8411 - val_loss: 0.6778 - val_accuracy: 0.8318\n",
            "Epoch 37/150\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.6110 - accuracy: 0.8417 - val_loss: 0.6168 - val_accuracy: 0.8457\n",
            "Epoch 38/150\n",
            "781/781 [==============================] - 100s 128ms/step - loss: 0.6155 - accuracy: 0.8411 - val_loss: 0.6405 - val_accuracy: 0.8395\n",
            "Epoch 39/150\n",
            "781/781 [==============================] - 106s 136ms/step - loss: 0.6152 - accuracy: 0.8379 - val_loss: 0.7340 - val_accuracy: 0.8182\n",
            "Epoch 40/150\n",
            "781/781 [==============================] - 100s 129ms/step - loss: 0.5993 - accuracy: 0.8429 - val_loss: 0.6577 - val_accuracy: 0.8341\n",
            "Epoch 41/150\n",
            "781/781 [==============================] - 94s 120ms/step - loss: 0.6190 - accuracy: 0.8405 - val_loss: 0.6932 - val_accuracy: 0.8268\n",
            "Epoch 42/150\n",
            "781/781 [==============================] - 91s 117ms/step - loss: 0.6085 - accuracy: 0.8432 - val_loss: 0.7070 - val_accuracy: 0.8218\n",
            "Epoch 43/150\n",
            "781/781 [==============================] - 94s 121ms/step - loss: 0.6021 - accuracy: 0.8446 - val_loss: 0.6377 - val_accuracy: 0.8419\n",
            "Epoch 44/150\n",
            "781/781 [==============================] - 92s 117ms/step - loss: 0.6074 - accuracy: 0.8457 - val_loss: 0.6060 - val_accuracy: 0.8515\n",
            "Epoch 45/150\n",
            "781/781 [==============================] - 104s 134ms/step - loss: 0.6031 - accuracy: 0.8431 - val_loss: 0.8334 - val_accuracy: 0.7792\n",
            "Epoch 46/150\n",
            "781/781 [==============================] - 99s 127ms/step - loss: 0.6032 - accuracy: 0.8439 - val_loss: 0.6861 - val_accuracy: 0.8301\n",
            "Epoch 47/150\n",
            "781/781 [==============================] - 100s 128ms/step - loss: 0.5982 - accuracy: 0.8440 - val_loss: 0.6236 - val_accuracy: 0.8463\n",
            "Epoch 48/150\n",
            "781/781 [==============================] - 96s 123ms/step - loss: 0.6003 - accuracy: 0.8454 - val_loss: 0.6028 - val_accuracy: 0.8450\n",
            "Epoch 49/150\n",
            "781/781 [==============================] - 97s 124ms/step - loss: 0.5937 - accuracy: 0.8473 - val_loss: 0.5617 - val_accuracy: 0.8610\n",
            "Epoch 50/150\n",
            "781/781 [==============================] - 101s 130ms/step - loss: 0.6015 - accuracy: 0.8445 - val_loss: 0.5926 - val_accuracy: 0.8518\n",
            "Epoch 51/150\n",
            "781/781 [==============================] - 98s 126ms/step - loss: 0.6055 - accuracy: 0.8448 - val_loss: 0.6553 - val_accuracy: 0.8412\n",
            "Epoch 52/150\n",
            "781/781 [==============================] - 97s 124ms/step - loss: 0.5993 - accuracy: 0.8467 - val_loss: 0.6178 - val_accuracy: 0.8497\n",
            "Epoch 53/150\n",
            "781/781 [==============================] - 103s 132ms/step - loss: 0.5952 - accuracy: 0.8480 - val_loss: 0.5726 - val_accuracy: 0.8632\n",
            "Epoch 54/150\n",
            "781/781 [==============================] - 102s 130ms/step - loss: 0.5929 - accuracy: 0.8480 - val_loss: 0.6844 - val_accuracy: 0.8300\n",
            "Epoch 55/150\n",
            "781/781 [==============================] - 100s 128ms/step - loss: 0.6012 - accuracy: 0.8469 - val_loss: 0.6572 - val_accuracy: 0.8428\n",
            "Epoch 56/150\n",
            "781/781 [==============================] - 100s 128ms/step - loss: 0.5918 - accuracy: 0.8493 - val_loss: 0.7122 - val_accuracy: 0.8275\n",
            "Epoch 57/150\n",
            "781/781 [==============================] - 101s 129ms/step - loss: 0.6006 - accuracy: 0.8463 - val_loss: 0.6120 - val_accuracy: 0.8537\n",
            "Epoch 58/150\n",
            "781/781 [==============================] - 101s 129ms/step - loss: 0.5887 - accuracy: 0.8509 - val_loss: 0.5975 - val_accuracy: 0.8543\n",
            "Epoch 59/150\n",
            "781/781 [==============================] - 95s 121ms/step - loss: 0.5886 - accuracy: 0.8497 - val_loss: 0.5865 - val_accuracy: 0.8561\n",
            "Epoch 60/150\n",
            "781/781 [==============================] - 96s 123ms/step - loss: 0.5905 - accuracy: 0.8497 - val_loss: 0.6332 - val_accuracy: 0.8415\n",
            "Epoch 61/150\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.5895 - accuracy: 0.8500 - val_loss: 0.5874 - val_accuracy: 0.8553\n",
            "Epoch 62/150\n",
            "781/781 [==============================] - 93s 119ms/step - loss: 0.5949 - accuracy: 0.8488 - val_loss: 0.5882 - val_accuracy: 0.8548\n",
            "Epoch 63/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.5797 - accuracy: 0.8519 - val_loss: 0.5915 - val_accuracy: 0.8568\n",
            "Epoch 64/150\n",
            "781/781 [==============================] - 93s 120ms/step - loss: 0.5837 - accuracy: 0.8515 - val_loss: 0.5905 - val_accuracy: 0.8525\n",
            "Epoch 65/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.5843 - accuracy: 0.8512 - val_loss: 0.6354 - val_accuracy: 0.8454\n",
            "Epoch 66/150\n",
            "781/781 [==============================] - 93s 120ms/step - loss: 0.5917 - accuracy: 0.8503 - val_loss: 0.5601 - val_accuracy: 0.8633\n",
            "Epoch 67/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.5812 - accuracy: 0.8535 - val_loss: 0.6246 - val_accuracy: 0.8452\n",
            "Epoch 68/150\n",
            "781/781 [==============================] - 92s 117ms/step - loss: 0.5845 - accuracy: 0.8511 - val_loss: 0.5809 - val_accuracy: 0.8573\n",
            "Epoch 69/150\n",
            "781/781 [==============================] - 89s 114ms/step - loss: 0.5812 - accuracy: 0.8545 - val_loss: 0.6433 - val_accuracy: 0.8398\n",
            "Epoch 70/150\n",
            "781/781 [==============================] - 90s 116ms/step - loss: 0.5819 - accuracy: 0.8540 - val_loss: 0.6168 - val_accuracy: 0.8503\n",
            "Epoch 71/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.5785 - accuracy: 0.8542 - val_loss: 0.5862 - val_accuracy: 0.8563\n",
            "Epoch 72/150\n",
            "781/781 [==============================] - 90s 115ms/step - loss: 0.5732 - accuracy: 0.8571 - val_loss: 0.6306 - val_accuracy: 0.8440\n",
            "Epoch 73/150\n",
            "781/781 [==============================] - 90s 115ms/step - loss: 0.5721 - accuracy: 0.8565 - val_loss: 0.5930 - val_accuracy: 0.8554\n",
            "Epoch 74/150\n",
            "781/781 [==============================] - 89s 114ms/step - loss: 0.5795 - accuracy: 0.8543 - val_loss: 0.6054 - val_accuracy: 0.8530\n",
            "Epoch 75/150\n",
            "781/781 [==============================] - 90s 115ms/step - loss: 0.5791 - accuracy: 0.8550 - val_loss: 0.6573 - val_accuracy: 0.8353\n",
            "Epoch 76/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.5837 - accuracy: 0.8537 - val_loss: 0.5701 - val_accuracy: 0.8647\n",
            "Epoch 77/150\n",
            "781/781 [==============================] - 103s 131ms/step - loss: 0.5472 - accuracy: 0.8636 - val_loss: 0.5492 - val_accuracy: 0.8703\n",
            "Epoch 78/150\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.5259 - accuracy: 0.8691 - val_loss: 0.5572 - val_accuracy: 0.8654\n",
            "Epoch 79/150\n",
            "781/781 [==============================] - 92s 117ms/step - loss: 0.5072 - accuracy: 0.8770 - val_loss: 0.5308 - val_accuracy: 0.8762\n",
            "Epoch 80/150\n",
            "781/781 [==============================] - 88s 113ms/step - loss: 0.5041 - accuracy: 0.8772 - val_loss: 0.5219 - val_accuracy: 0.8758\n",
            "Epoch 81/150\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.5031 - accuracy: 0.8752 - val_loss: 0.5284 - val_accuracy: 0.8747\n",
            "Epoch 82/150\n",
            "781/781 [==============================] - 91s 116ms/step - loss: 0.4800 - accuracy: 0.8823 - val_loss: 0.5089 - val_accuracy: 0.8787\n",
            "Epoch 83/150\n",
            "781/781 [==============================] - 91s 117ms/step - loss: 0.4912 - accuracy: 0.8769 - val_loss: 0.5607 - val_accuracy: 0.8593\n",
            "Epoch 84/150\n",
            "781/781 [==============================] - 93s 120ms/step - loss: 0.4889 - accuracy: 0.8784 - val_loss: 0.4912 - val_accuracy: 0.8807\n",
            "Epoch 85/150\n",
            "781/781 [==============================] - 89s 114ms/step - loss: 0.4830 - accuracy: 0.8806 - val_loss: 0.5733 - val_accuracy: 0.8581\n",
            "Epoch 86/150\n",
            "781/781 [==============================] - 91s 117ms/step - loss: 0.4828 - accuracy: 0.8779 - val_loss: 0.5296 - val_accuracy: 0.8684\n",
            "Epoch 87/150\n",
            "781/781 [==============================] - 91s 117ms/step - loss: 0.4801 - accuracy: 0.8781 - val_loss: 0.5752 - val_accuracy: 0.8567\n",
            "Epoch 88/150\n",
            "781/781 [==============================] - 90s 115ms/step - loss: 0.4801 - accuracy: 0.8795 - val_loss: 0.5120 - val_accuracy: 0.8709\n",
            "Epoch 89/150\n",
            "781/781 [==============================] - 95s 122ms/step - loss: 0.4714 - accuracy: 0.8831 - val_loss: 0.5182 - val_accuracy: 0.8732\n",
            "Epoch 90/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.4752 - accuracy: 0.8768 - val_loss: 0.5778 - val_accuracy: 0.8570\n",
            "Epoch 91/150\n",
            "781/781 [==============================] - 86s 109ms/step - loss: 0.4742 - accuracy: 0.8778 - val_loss: 0.4841 - val_accuracy: 0.8830\n",
            "Epoch 92/150\n",
            "781/781 [==============================] - 91s 116ms/step - loss: 0.4727 - accuracy: 0.8793 - val_loss: 0.4762 - val_accuracy: 0.8837\n",
            "Epoch 93/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.4613 - accuracy: 0.8826 - val_loss: 0.4891 - val_accuracy: 0.8782\n",
            "Epoch 94/150\n",
            "781/781 [==============================] - 92s 118ms/step - loss: 0.4682 - accuracy: 0.8794 - val_loss: 0.4670 - val_accuracy: 0.8869\n",
            "Epoch 95/150\n",
            "781/781 [==============================] - 93s 119ms/step - loss: 0.4550 - accuracy: 0.8853 - val_loss: 0.5487 - val_accuracy: 0.8634\n",
            "Epoch 96/150\n",
            "781/781 [==============================] - 93s 120ms/step - loss: 0.4530 - accuracy: 0.8859 - val_loss: 0.5174 - val_accuracy: 0.8709\n",
            "Epoch 97/150\n",
            "781/781 [==============================] - 88s 113ms/step - loss: 0.4657 - accuracy: 0.8802 - val_loss: 0.5219 - val_accuracy: 0.8717\n",
            "Epoch 98/150\n",
            "781/781 [==============================] - 90s 115ms/step - loss: 0.4579 - accuracy: 0.8814 - val_loss: 0.4899 - val_accuracy: 0.8811\n",
            "Epoch 99/150\n",
            "781/781 [==============================] - 89s 114ms/step - loss: 0.4534 - accuracy: 0.8830 - val_loss: 0.4658 - val_accuracy: 0.8822\n",
            "Epoch 100/150\n",
            "781/781 [==============================] - 88s 113ms/step - loss: 0.4585 - accuracy: 0.8822 - val_loss: 0.4524 - val_accuracy: 0.8894\n",
            "Epoch 101/150\n",
            "781/781 [==============================] - 87s 112ms/step - loss: 0.4538 - accuracy: 0.8814 - val_loss: 0.5217 - val_accuracy: 0.8651\n",
            "Epoch 102/150\n",
            "781/781 [==============================] - 91s 117ms/step - loss: 0.4425 - accuracy: 0.8866 - val_loss: 0.5105 - val_accuracy: 0.8734\n",
            "Epoch 103/150\n",
            "781/781 [==============================] - 89s 114ms/step - loss: 0.4338 - accuracy: 0.8894 - val_loss: 0.4974 - val_accuracy: 0.8757\n",
            "Epoch 104/150\n",
            "781/781 [==============================] - 85s 109ms/step - loss: 0.4236 - accuracy: 0.8923 - val_loss: 0.4737 - val_accuracy: 0.8838\n",
            "Epoch 105/150\n",
            "781/781 [==============================] - 86s 111ms/step - loss: 0.4253 - accuracy: 0.8899 - val_loss: 0.5044 - val_accuracy: 0.8747\n",
            "Epoch 106/150\n",
            "781/781 [==============================] - 89s 113ms/step - loss: 0.4187 - accuracy: 0.8942 - val_loss: 0.5068 - val_accuracy: 0.8745\n",
            "Epoch 107/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.4243 - accuracy: 0.8923 - val_loss: 0.4789 - val_accuracy: 0.8855\n",
            "Epoch 108/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.4155 - accuracy: 0.8944 - val_loss: 0.4955 - val_accuracy: 0.8741\n",
            "Epoch 109/150\n",
            "781/781 [==============================] - 85s 109ms/step - loss: 0.4144 - accuracy: 0.8944 - val_loss: 0.4655 - val_accuracy: 0.8850\n",
            "Epoch 110/150\n",
            "781/781 [==============================] - 85s 108ms/step - loss: 0.4121 - accuracy: 0.8945 - val_loss: 0.5191 - val_accuracy: 0.8716\n",
            "Epoch 111/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.4078 - accuracy: 0.8964 - val_loss: 0.4326 - val_accuracy: 0.8962\n",
            "Epoch 112/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.4148 - accuracy: 0.8932 - val_loss: 0.4788 - val_accuracy: 0.8822\n",
            "Epoch 113/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.4100 - accuracy: 0.8961 - val_loss: 0.4870 - val_accuracy: 0.8819\n",
            "Epoch 114/150\n",
            "781/781 [==============================] - 84s 107ms/step - loss: 0.4090 - accuracy: 0.8950 - val_loss: 0.4837 - val_accuracy: 0.8784\n",
            "Epoch 115/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.4145 - accuracy: 0.8938 - val_loss: 0.4615 - val_accuracy: 0.8853\n",
            "Epoch 116/150\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.4095 - accuracy: 0.8924 - val_loss: 0.4690 - val_accuracy: 0.8838\n",
            "Epoch 117/150\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.4012 - accuracy: 0.8951 - val_loss: 0.4552 - val_accuracy: 0.8878\n",
            "Epoch 118/150\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.4038 - accuracy: 0.8952 - val_loss: 0.4948 - val_accuracy: 0.8749\n",
            "Epoch 119/150\n",
            "781/781 [==============================] - 86s 110ms/step - loss: 0.4062 - accuracy: 0.8941 - val_loss: 0.4706 - val_accuracy: 0.8815\n",
            "Epoch 120/150\n",
            "781/781 [==============================] - 85s 108ms/step - loss: 0.4052 - accuracy: 0.8948 - val_loss: 0.5175 - val_accuracy: 0.8725\n",
            "Epoch 121/150\n",
            "781/781 [==============================] - 85s 109ms/step - loss: 0.3919 - accuracy: 0.8976 - val_loss: 0.5051 - val_accuracy: 0.8735\n",
            "Epoch 122/150\n",
            "781/781 [==============================] - 83s 107ms/step - loss: 0.4084 - accuracy: 0.8927 - val_loss: 0.4493 - val_accuracy: 0.8870\n",
            "Epoch 123/150\n",
            "781/781 [==============================] - 85s 109ms/step - loss: 0.3886 - accuracy: 0.8979 - val_loss: 0.4887 - val_accuracy: 0.8746\n",
            "Epoch 124/150\n",
            "781/781 [==============================] - 84s 107ms/step - loss: 0.4005 - accuracy: 0.8953 - val_loss: 0.4496 - val_accuracy: 0.8856\n",
            "Epoch 125/150\n",
            "781/781 [==============================] - 85s 108ms/step - loss: 0.4023 - accuracy: 0.8960 - val_loss: 0.4826 - val_accuracy: 0.8801\n",
            "Epoch 126/150\n",
            "781/781 [==============================] - 84s 107ms/step - loss: 0.3904 - accuracy: 0.8960 - val_loss: 0.4659 - val_accuracy: 0.8861\n",
            "Epoch 127/150\n",
            "781/781 [==============================] - 84s 107ms/step - loss: 0.3928 - accuracy: 0.8966 - val_loss: 0.4677 - val_accuracy: 0.8827\n",
            "Epoch 128/150\n",
            "781/781 [==============================] - 85s 109ms/step - loss: 0.4009 - accuracy: 0.8976 - val_loss: 0.4812 - val_accuracy: 0.8809\n",
            "Epoch 129/150\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.3887 - accuracy: 0.8983 - val_loss: 0.5115 - val_accuracy: 0.8708\n",
            "Epoch 130/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.3996 - accuracy: 0.8964 - val_loss: 0.4229 - val_accuracy: 0.8908\n",
            "Epoch 131/150\n",
            "781/781 [==============================] - 84s 107ms/step - loss: 0.3938 - accuracy: 0.8983 - val_loss: 0.4353 - val_accuracy: 0.8906\n",
            "Epoch 132/150\n",
            "781/781 [==============================] - 84s 108ms/step - loss: 0.3958 - accuracy: 0.8957 - val_loss: 0.4892 - val_accuracy: 0.8796\n",
            "Epoch 133/150\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.3905 - accuracy: 0.8981 - val_loss: 0.4518 - val_accuracy: 0.8877\n",
            "Epoch 134/150\n",
            "781/781 [==============================] - 84s 107ms/step - loss: 0.3898 - accuracy: 0.8986 - val_loss: 0.4854 - val_accuracy: 0.8776\n",
            "Epoch 135/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3941 - accuracy: 0.8959 - val_loss: 0.4142 - val_accuracy: 0.8974\n",
            "Epoch 136/150\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.3860 - accuracy: 0.8988 - val_loss: 0.4799 - val_accuracy: 0.8787\n",
            "Epoch 137/150\n",
            "781/781 [==============================] - 82s 104ms/step - loss: 0.3816 - accuracy: 0.9027 - val_loss: 0.4495 - val_accuracy: 0.8856\n",
            "Epoch 138/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3815 - accuracy: 0.9018 - val_loss: 0.4632 - val_accuracy: 0.8803\n",
            "Epoch 139/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3889 - accuracy: 0.8973 - val_loss: 0.4455 - val_accuracy: 0.8862\n",
            "Epoch 140/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3865 - accuracy: 0.8997 - val_loss: 0.4675 - val_accuracy: 0.8808\n",
            "Epoch 141/150\n",
            "781/781 [==============================] - 83s 106ms/step - loss: 0.3825 - accuracy: 0.8986 - val_loss: 0.4408 - val_accuracy: 0.8907\n",
            "Epoch 142/150\n",
            "781/781 [==============================] - 82s 105ms/step - loss: 0.3863 - accuracy: 0.8982 - val_loss: 0.4984 - val_accuracy: 0.8733\n",
            "Epoch 143/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.3857 - accuracy: 0.8992 - val_loss: 0.4513 - val_accuracy: 0.8856\n",
            "Epoch 144/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.3785 - accuracy: 0.9016 - val_loss: 0.4809 - val_accuracy: 0.8818\n",
            "Epoch 145/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.3775 - accuracy: 0.9014 - val_loss: 0.5132 - val_accuracy: 0.8611\n",
            "Epoch 146/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.3868 - accuracy: 0.8979 - val_loss: 0.4710 - val_accuracy: 0.8807\n",
            "Epoch 147/150\n",
            "781/781 [==============================] - 80s 103ms/step - loss: 0.3823 - accuracy: 0.8988 - val_loss: 0.4694 - val_accuracy: 0.8797\n",
            "Epoch 148/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.3848 - accuracy: 0.8967 - val_loss: 0.4444 - val_accuracy: 0.8872\n",
            "Epoch 149/150\n",
            "781/781 [==============================] - 81s 103ms/step - loss: 0.3862 - accuracy: 0.8995 - val_loss: 0.4484 - val_accuracy: 0.8876\n",
            "Epoch 150/150\n",
            "781/781 [==============================] - 81s 104ms/step - loss: 0.3849 - accuracy: 0.8995 - val_loss: 0.4532 - val_accuracy: 0.8871\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd81f0d75d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "batch_size = 64\n",
        " \n",
        "opt_rms = keras.optimizers.RMSprop(lr=0.001,decay=1e-6)\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "model_2.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=150,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toqzAGnGIJwM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf5a48b-079e-40b8-9e9b-ce36fdf97e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.4531835913658142\n",
            "Test accuracy: 0.8870999813079834\n"
          ]
        }
      ],
      "source": [
        "# Test the model on test data\n",
        "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj7pfNbBIJwN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Project_Bonus_Improved.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}